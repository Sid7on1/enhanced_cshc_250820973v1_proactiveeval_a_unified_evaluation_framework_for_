{
  "agent_id": "coder4",
  "task_id": "task_2",
  "files": [
    {
      "name": "config.py",
      "purpose": "Agent and environment configuration",
      "priority": "high"
    },
    {
      "name": "requirements.txt",
      "purpose": "Python dependencies",
      "priority": "high"
    }
  ],
  "project_info": {
    "project_name": "enhanced_cs.HC_2508.20973v1_ProactiveEval_A_Unified_Evaluation_Framework_for_",
    "project_type": "agent",
    "description": "Enhanced AI project based on cs.HC_2508.20973v1_ProactiveEval-A-Unified-Evaluation-Framework-for- with content analysis. Detected project type: agent (confidence score: 8 matches).",
    "key_algorithms": [
      "Started",
      "Each",
      "Focused",
      "Goal",
      "Non-Thinking",
      "Future",
      "Evaluation",
      "Quickly",
      "Synthetic",
      "Sketching"
    ],
    "main_libraries": [
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: cs.HC_2508.20973v1_ProactiveEval-A-Unified-Evaluation-Framework-for-.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nProactiveEval: A Unified Evaluation Framework for\nProactive Dialogue Agents\nTianjian Liu1, Fanqi Wan1, Jiajian Guo1, Xiaojun Quan1\n1Sun Yat-sen University\nGuangzhou, China\n{liutj9, wanfq, guojj59 }@mail2.sysu.edu.cn, quanxj3@mail.sysu.edu.cn\nAbstract\nProactive dialogue has emerged as a critical and challeng-\ning research problem in advancing large language models\n(LLMs). Existing works predominantly focus on domain-\nspecific or task-oriented scenarios, which leads to fragmented\nevaluations and limits the comprehensive exploration of mod-\nels\u2019 proactive conversation abilities. In this work, we propose\nProactiveEval, a unified framework designed for evaluating\nproactive dialogue capabilities of LLMs. This framework de-\ncomposes proactive dialogue into target planning and dia-\nlogue guidance, establishing evaluation metrics across vari-\nous domains. Moreover, it also enables the automatic gener-\nation of diverse and challenging evaluation data. Based on\nthe proposed framework, we develop 328 evaluation envi-\nronments spanning 6 distinct domains. Through experiments\nwith 22 different types of LLMs, we show that DeepSeek-\nR1 and Claude-3.7-Sonnet exhibit exceptional performance\non target planning and dialogue guidance tasks, respectively.\nFinally, we investigate how reasoning capabilities influence\nproactive behaviors and discuss their implications for future\nmodel development.\nCode \u2014 https://github.com/liutj9/ProactiveEval\nIntroduction\nDialogue agents powered by large language models (LLMs)\nhave demonstrated remarkable abilities in various dialogue\ntasks (Wang et al. 2024; Niu et al. 2024; Zhang et al. 2024c).\nHowever, these models typically interact with users in a re-\nactive manner, where users are required to initiate and guide\nthe conversation by integrating complex context ( e.g., per-\nsonal state, external environment, and agent\u2019s information).\nThis user-initiated paradigm imposes cognitive demands on\nparticipants (Wan et al. 2024), reduces sustained motivation\n(Croes and Antheunis 2021), and limits agents potential for\nautonomous problem solving (Lu et al. 2024).\nTherefore, proactive dialogue agents1(Wang et al. 2023;\nDeng et al. 2023a; Lu et al. 2024) have attracted growing re-\nsearch attention. As shown in Figure 1, proactive agents can\nanticipate user needs, formulate adaptive plans, and guide\nconversations towards specific targets (Deng et al. 2025).\nFor instance, when the user is working with smart glasses,\n1For brevity, \u201cproactive dialogue agents\u201d are hereafter abbrevi-\nated as \u201cproactive agents.\u201d\nUser Information\nTrigger Factor\nI notice you've been working for 3 hours \nstraight without a break. Would you like to \ntake a mindfulness break ?\nYou're right, I could use a break. A quick \nmindfulness session sounds like a great idea.\nPerfect! Let's do a simple breathing \nexercise. Find a comfortable position, \u2026\u2026\nSure, I'll give that a try. I'll take those \ndeep breaths now, thanks for guiding me.Task 1: Target Planning\nTarget: Encourage a mindfulness break.\nSub-targets: \n1. Detect stress signs, \n2. Prompt take a break, \n3. Guide quick breathing exercise.\nWork 3 hoursTask 2: Dialogue GuidanceInput\nInputEnvironment\nSlouched  \nPosture\nSlight Tremor Job: Software Engineer \nTrouble: Work Deadline. \nFigure 1: Interaction diagram for proactive dialogue agents,\nwhich can anticipate user needs based on the environment\ninformation, formulate hierarchical plans, and guide the con-\nversation towards specific targets.\nthe agent can recognize potential challenges based on user\nbehavior captured by the device and proactively offer accu-\nrate assistance and care without explicit user requests (Yang\net al. 2025b). This interaction paradigm noticeably enhances\nthe efficiency of human-AI collaboration and reduces user\ncognitive load (Chaves and Gerosa 2021).\nRecent research has explored methods to enhance the\nproactive capabilities of LLMs across varied scenarios. For\ninstance, Deng et al. (2023b, 2024) employ strategies like\nchain-of-thought (CoT) reasoning and plug-and-play plan-\nners to strengthen LLMs\u2019 ability to autonomously plan\nand act in conversational contexts. Concurrently, Liu et al.\n(2024b); Cai et al. (2025); Chen et al. (2024) focus on de-\nveloping proactive agents for specialized domains, such as\nemotional support dialogues, smart glasses interfaces, and\nsystem operation support. Despite these advances, existing\nevaluation frameworks often rely on datasets for specific\ntasks and domains, employ inconsistent evaluation crite-\nria, and utilize disparate metrics. The lack of standardized\nformalizations and general benchmarks poses challenges in\ncomparing the proactivity of different models in a compre-\nhensive way. Hence, there is an urgent need for a unifiedarXiv:2508.20973v1  [cs.CL]  28 Aug 2025\n\n--- Page 2 ---\nDomain Abbr. Brief Description\nRecommendation (Liu et al. 2021b) Rec. Recommend products, hobbies, or work based on common interests.\nPersuasion (Jin et al. 2024) Per. Guide the conversation to persuade users to change their state.\nAmbiguous Instruction (Deng et al. 2023b) AI. Seek clarification about vague elements in the user\u2019s instructions.\nLong-term Follow-up (Liu et al. 2024b) LF. Inquiries and check user states based on previous dialogue history.\nSystem Operation (Lu et al. 2024) Sys. Assist users in solving the system problem based on their operation.\nGlasses Assistant (Cai et al. 2025) GAs. Provide real-time assistance from observation on smart glasses.\nTable 1: The proactive dialogue domains in ProactiveEval.\nevaluation framework to assess and advance LLMs\u2019 proac-\ntive dialogue abilities across domains.\nTo address the above challenges, we propose ProactiveE-\nval, a unified evaluation framework for assessing proactive\ndialogue capabilities of LLMs. Specifically, ProactiveEval\ndivides proactive dialogue into two key tasks: target plan-\nning and dialogue guidance. For each task, we use \u201cLLM-\nas-a-judge\u201d (Zheng et al. 2023) with task-specific evaluation\ndimensions for comprehensive assessment. Additionally, we\npropose an evaluation data synthesis framework, which can\nautomatically generate diverse and challenging evaluation\ndata in different domains. This framework leverages three\nkey innovations: (1) a hierarchical environment topic tree to\nenhance the diversity of the synthesized environment, (2) a\ntarget ensemble technique to refine evaluation data, and (3)\nadversarial strategies like obfuscation rewriting and noise in-\njection to increase environmental difficulty.\nBuilding upon this framework, we establish 328 evalu-\nation environments spanning six distinct domains, one of\nwhich lacked public benchmarks previously. We apply this\ndataset to assess the capabilities of 22 frontier LLMs, includ-\ning GPTs, Llamas, Claude, DeepSeek, Gemini, Grok, and\nQwens. Our analysis shows that DeepSeek-R1 and Claude-\n3.7-Sonnet achieve top performance in target planning and\ndialogue guidance tasks, respectively. Notably, we focus on\nexploring the impact of the \u201cthinking behavior\u201d (Xu et al.\n2025; OpenAI 2024) on the proactive dialogue capabilities.\nWhile these reasoning mechanisms prove beneficial for tar-\nget planning, they show no measurable impact on dialogue\nguidance effectiveness, highlighting the limitations in cur-\nrent reasoning LLMs development.\nRelated Work\nProactive Dialogue\nIn proactive dialogue, LLMs are no longer passive assis-\ntants awaiting user input. Instead, they are capable of infer-\nring user needs from user information and trigger factor, en-\nabling them to proactively plan, initiate dialogue, and guide\nthe user toward the target. Several studies has explored var-\nious facets of model capabilities. For instance, some bench-\nmarks are developed to assess the model\u2019s ability to clarify\nambiguity (Qian et al. 2024; Zhang et al. 2024b) or guide\nusers in complex tasks like negotiation (Deng et al. 2024;\nZhang et al. 2024a). Other studies have focused on prereq-\nuisite skills such as goal prediction and planning before di-\nalogue (Zhang et al. 2024d; Zheng et al. 2024). However,\nthese efforts are fragmented, with a lack of standardizationin environments, formats, and metrics, hindering a compre-\nhensive understanding of a model\u2019s overall proactivity.\nBuilding on these capabilities, recent works develop\nproactive agents for real-world applications, such as provid-\ning life guidance (Li et al. 2025a) or offering reminders via\nsmart glasses (Cai et al. 2025). However, their evaluation\nis often constrained by the absence of robust benchmarks\nand a heavy reliance on small-scale, high-cost user stud-\nies. Motivated by the challenges of fragmented capability\nassessment and limited agent evaluation, this work proposes\na general and comprehensive framework to establish a uni-\nfied methodology for evaluating proactive dialogue.\nInteractive Benchmarks\nPrevious dialogue benchmarks typically evaluate turn-level\nperformance based on fixed contexts and reference re-\nsponses (Liu et al. 2021a; Bai et al. 2024; Jin et al. 2024).\nHowever, to assess models\u2019 dialogue abilities in real-world\nconditions, an increasing number of studies have applied\nthe interactive benchmarks to measure dialogue-level per-\nformance of models (Zhou et al. 2023b; Aluffi et al. 2025;\nCastillo-Bolado et al. 2024). Specifically, they require the\nevaluated model to chat with a standardized simulated user\ndynamically, and ultimately assess the models performance\nthroughout the entire conversation. For example, \u03c4-bench\n(Yao et al. 2024) facilitates multi-turn dialogues between\nthe model and a simulated user to evaluate the model\u2019s tool-\ncalling capabilities in interaction. In proactive dialogue eval-\nuation, Zhang et al. (2024a) instructs models to interact mul-\ntiple turns with simulated users who have different person-\nalities, ultimately evaluating the dialogue guidance of the\nmodel. Inspired by these studies, our work also employs in-\nteractive benchmarks in the framework, where the model\nwill initiate proactive dialogue and proactively guide vari-\nous users to the target in the evaluation environment.\nTask Definitions\nTo construct a general evaluation framework, we first struc-\nturally unify the existing proactive dialogue domains and\ntasks. Table 1 presents 6 proactive dialogue domains derived\nfrom previous work. Based on existing works (Deng et al.\n2023b, 2025), we decompose proactive dialogue into two\nsequential tasks: target planning anddialogue guidance .\nTarget Planning\nIn proactive agents, the target planning task requires the\nmodel to formulate both a primary objective Tand a se-\nquence of sub-targets Sbased on its understanding of the\n\n--- Page 3 ---\n(a)Environment Topic Tree\nPersu\nasionCareer Development\nBehavior \nChangeFinancial \nPlanningThought Discussion\nSavings \nTechniques\n\u2026\u2026\nInitialize\nExpand\nManual \nInitAI ExpandManual \nCheck\nStep 1: Topic Tree Construction Step 2: Environment & Target Generation\nStep 3: Environment RefinementSeed Data\n\u2022Environment & Target Examples\n\u2022Domain Description\nEnvironment\nGeneration\n User \nInformation\nTrigger FactorReference Target\nGeneration\nTarget 1\nTarget 2\nTarget 5\nLLMHigh Temperature \nSampling LLM\u2026\u2026Reference \nTargetEnsemble\nSeed Data\n\u2022Environment variants examples\nUser Information\nTrigger Factor\nReference TargetEvaluation Data\nObfuscation Rewrite \nNoise Injection\nGPT -4o\nQwen2.5 -32B -Instruct\nQwen2.5 -14B -Instruct\nMajority Predict Right (too easy)ICL shots & Requirements\nTest\nUpdateLLMMinority\nRight\nCheck \nCorrectness\nMajority \nJudge True\nFinal Evaluation\nDataset(a)\n(b)\n5 turns\nFigure 2: Overview of the evaluation dataset generation pipeline. The pipeline is mainly divided into (a) data synthesis: gener-\nating the environment and reference target based on the topic tree for evaluation; (b) data refinement: improving the difficulty\nof the data through obfuscation rewrite and noisy injection to produce the final dataset.\nenvironmental context E. Here, Trepresents the agents in-\ntended proactive action to accomplish a predefined goal,\nwhile Sconstitutes the stepwise plan for executing T. This\nprocess is formally defined as:\nT, S =F\u03b8M(U, F|(U, F )\u2208E), (1)\nwhere \u03b8Mrefers to the models parameters, and (U, F )de-\nnotes inputs from the environment E, including user infor-\nmation Uand trigger factors Fthat motivates the agent to\ninitiate and guide the dialogue.\nFor evaluation, we employ a reference-based \u201cLLM-as-a-\njudge\u201d method (Zhang et al. 2025; Li et al. 2025b) to assess\nthe quality of generated targets and sub-targets. Particularly,\nthe judge model receives the environment E, the generated\ntarget Tgand sub-targets Sg, as well as the reference tar-\ngetTrand sub-targets Srthat represent high-quality proac-\ntive dialogue targets in this environment. By comparing the\ngeneration with the reference, the model assigns a score be-\ntween 1 and 10, where higher scores indicate superior qual-\nity, with 10 denoting generated content surpassing the refer-\nence standard in the given environment.\nDialogue Guidance\nAfter target planning, the model needs to initiate the dia-\nlogue and guide the user to the target. It receive the environ-\nment E, target T, sub-targets S, and dialogue context Cto\nconduct dialogue Dwith the simulated user \u03b8U.\nThis task employs an interactive evaluation, where the\nsimulated user dynamically responds to the model, based\non environment E, dialogue context C, and an adjustableagreeableness level A. To simulate diverse users, we adopt\nAgreeableness from the Big Five personality traits (Costa Jr,\nMcCrae, and Dye 1991), in three tiers: \u201clow\u201d, \u201cmedium\u201d,\nand \u201chigh\u201d. A lower agreeableness level signifies stronger\nresistance to the model\u2019s guidance, thus increasing task dif-\nficulty and realism. The dialogue terminates upon reaching\ntarget Tor a maximum of Iturns. The dialogue at each turn\nican be formulated as:\nDi=I\u03b8M,\u03b8U(E, T, S, C, A ). (2)\nAfter the dialogue, the judge model will evaluate the guid-\nance exhibited by the model in the dialogue D, based on the\nenvironment E, the target T, and the sub-targets S. Refer-\nring to existing works on proactive dialogue (Deng et al.\n2024; Wang et al. 2023; Zhang et al. 2024a; Liu et al.\n2024b), we specify the following evaluation dimensions:\n\u2022Effectiveness : The model needs to guide users step by\nstep toward the target, rather than providing all things to\nthe user in a single turn.\n\u2022Personalization : The model should give guidance based\non user information, rather than offering generic advice.\n\u2022Tone : The model needs to apply active and contextually\nappropriate tones to initiate and guide dialogue.\n\u2022Engagement : The model should keep messages clear and\nconcise to improve user understanding and engagement.\n\u2022Naturalness : The model should make messages conver-\nsational, avoiding unnatural formats or metadata leaks.\nThe detailed standards for each dimension are presented\nin supplementary materials. Finally, the judge model refers\n\n--- Page 4 ---\nto the environment, target, dialogue, and standards across\ndifferent dimensions to give an overall guidance score be-\ntween 1 and 10. A higher score indicates stronger guidance.\nEvaluation Data Generation\nAs illustrated in Figure 2, our pipeline includes two stages:\ndata synthesis anddata refinement . First, the synthesis stage\ngenerates diverse environments guided by a topic tree and\ncreates high-quality reference targets by target ensemble.\nThen, the refinement stage identifies simple instances and\nincreases their complexity through obfuscation rewrite and\nnoise injection. The prompts and cases for each module are\ndetailed in the supplementary materials.\nEnvironment Topic Tree Construction\nWe employ human-AI collaboration to develop a hierarchi-\ncal topic structure that enhances synthetic environment di-\nversity (Wan et al. 2023; Cao et al. 2025). The framework\ninitiates with a root node denoting broad domains ( e.g., per-\nsuasion), while first-level sub-topics are derived from exist-\ning dialogue datasets. The LLM iteratively generates can-\ndidate sub-topics within configurable depth and branching\nconstraints. To maintain quality control and eliminate dupli-\ncation, these generated topics are validated and refined by\nresearchers rigorously. The final curated topic tree guides\nthe creation of specific evaluation environments.\nEnvironment & Target Generation\nThe evaluation data include an environment E, a reference\ntarget Tr, and sub-targets Sr. Consequently, we leverage the\nLLM to generate specific evaluation environments based on\nthe domain requirements, data examples, and the topics.\nFor the generation of reference targets and sub-targets,\nour framework aims to construct correct and reasonable tar-\ngets and sub-targets that serve as reliable references within\nthe given environment. Recognizing that individual model-\ngenerated plans often display complementary strengths and\nlimitations, we adopt a target ensemble approach to refine\nreference target. Specifically, the framework first performs\nhigh-temperature sampling to yield diverse candidate tar-\ngets{(T1, S1),(T2, S2), . . . , (Tn, Sn)}(with n= 5 in our\nwork). Next, the LLM evaluates the strengths and weak-\nnesses of each output from multiple dimensions. By com-\nbining the strengths and mitigating the weaknesses, the ref-\nerence target and sub-targets are derived.\nEnvironment Refinement\nIn this stage, we first evaluate the difficulty of the test envi-\nronments. Specifically, we deploy three models, with vary-\ning parameter scales, to act as reasoners of different capa-\nbilities. For each input environment, these models indepen-\ndently predict the target, denoted as tm. Then, a model will\nevaluate how many of the predicted targets tmconvey a sim-\nilar meaning to the reference target tr, determining the diffi-\nculty of the environment. Environments where the majority\nsuccessfully predict the target are classified as easy candi-\ndates requiring refinement.In real-world conditions, the environment received by\nmodels is often incomplete and fragmented, which is al-\nways filled with irrelevant noise. Therefore, in the refine-\nment, we first apply the obfuscation rewrite strategy, allow-\ning the LLM to transform the content into dispersed and de-\ntailed descriptions. The framework also applies noise injec-\ntion to introduce LLM-generated irrelevant information to\nthe environment. After the refinement, the test environment\nis surrounded by complex and disordered information, sig-\nnificantly increasing the difficulty of target planning. In this\nprocess, seed data manually crafted by researchers is pro-\nvided as examples to enhance the quality of rewriting and\nnoise injection. To improve the adaptability between refine-\nment and domains, each domain can provide specific rules\nin the obfuscation rewrite, which are presented in supple-\nmentary materials. To keep the reference\u2019s correctness, the\nrewrite and noise injection of trigger factor contain the origi-\nnal datas reference target, so that preventing from additional\nevents that lead to other targets.\nThe refinement process involves multiple iterations until\nfew or no models predict the target correctly, or until reach-\ning the maximum of 5 turns. Before incorporating into the\ndataset, we apply 5 leading LLMs to validate the correctness\nof the reference target. Only those where the majority judges\nthe reference as the best target form the final dataset.\nExperiments\nExperimental Setups\nTarget \nPlanning\nDialogue \nGuidance\nProactiveBench\nEnPL\nIn3\nPersuasionforGood\nTopDial\nCraigslistBargain\n\u2026\u2026\n\u2026\u2026\nRec.\n51\nPer.\n77\nAI.\n57\nLF.\n61\nSys.\n37\nGAs.\n45\nFair\n30\nHard\n21\nFair\n31\nHard\n46\nFair\n20\nHard\n37\nFair\n27\nHard\n34\nFair\n22\nHard\n15\nFair\n27\nHard\n18\nProactiveEval\nOurs\nFigure 3: The features and statistic for ProactiveEval. The\nGAs. (Glasses Assistant) domain lacks public benchmarks\nfor the proactive dialogue task before.\nDatasets. Based on the framework, we use GPT-4o (Hurst\net al. 2024) to synthesize ProactiveEval, including 328 eval-\nuation environments across 6 domains. Compared with pre-\nvious fragmented benchmarks, these data integrate all main-\nstream domains of proactive dialogue, featuring a unified\nformat and applicability to all tasks in proactive dialogue.\nThe statistic for dataset is presented in Figure 3. To stream-\nline evaluation, we categorize the dataset into two tiers: Fair\n(i.e., just one LLM predicts correctly) and Hard ( i.e., no\nLLM predicted correctly).\nProtocols. Based on the dataset, we assess 22 models with\ndifferent scales, including 5 thinking models and 6 hybrid\nthinking models. Table 2 shows the performance of all mod-\nels.Bold indicates the best in non-thinking model, while\n\n--- Page 5 ---\nModelsTarget Planning Dialogue Guidance\nAvg. Rec. Per. AI. LF. Sys. GAs Avg. Rec. Per. AI. LF. Sys. GAs.\nNon-Thinking Models\nQwen2.5-7B-Instruct 4.93 4.69 4.06 5.67 5.34 4.89 5.24 8.06 8.05 7.85 8.34 8.36 7.48 8.16\nQwen2.5-14B-Instruct 5.55 5.76 4.13 6.00 5.97 6.03 6.22 8.21 8.33 8.05 8.64 8.42 7.52 8.04\nQwen2.5-32B-Instruct 5.44 5.47 3.90 5.79 6.03 6.11 6.22 8.23 8.56 8.10 8.56 8.52 7.60 7.81\nLlama-3.1-8B-Instruct 5.87 5.55 4.84 6.67 6.39 5.95 6.20 8.39 8.84 8.06 8.61 8.39 7.93 8.46\nLlama-3.1-405B-Instruct 6.63 6.76 5.26 6.61 7.26 7.10 7.64 8.60 9.15 8.27 8.90 8.57 7.89 8.80\nGPT-4.1 6.86 6.90 5.25 7.29 7.36 7.54 7.76 8.61 9.03 8.37 8.87 8.76 8.08 8.43\nGrok-3 6.99 7.13 5.38 7.44 7.54 7.62 7.78 8.84 9.10 8.72 8.94 8.98 8.32 8.86\nDeepSeek-V3 6.54 6.96 5.94 6.04 6.07 7.27 7.84 8.78 8.78 8.60 8.99 8.98 8.52 8.79\nLlama-4-scout 6.02 5.71 5.29 6.16 6.49 6.41 6.56 8.53 8.94 8.35 8.65 8.44 8.03 8.74\nLlama-4-maverick 6.48 6.25 5.10 7.09 7.05 7.11 7.00 8.48 9.01 8.19 8.69 8.41 8.01 8.55\nQwen3-8B 6.05 6.35 4.52 6.23 6.39 6.86 6.97 8.50 8.70 8.36 8.84 8.82 7.58 8.40\nQwen3-14B 5.91 5.96 4.80 6.23 6.16 6.65 6.40 8.61 8.82 8.24 9.12 8.76 7.99 8.66\nQwen3-32B 6.67 6.86 5.29 6.54 6.84 7.65 8.02 8.61 8.77 8.42 8.91 8.16 7.97 8.74\nQwen3-235B-A22B 6.43 6.18 5.26 6.21 6.77 7.54 7.60 8.55 8.93 8.46 8.67 8.66 7.83 8.53\nQwen-3-235B-A22B-0725 6.91 7.08 6.25 6.79 6.51 7.81 7.82 8.98 9.36 8.84 9.40 8.85 8.42 8.88\nGemini-2.5-Flash-Preview 6.25 6.04 5.48 6.95 6.49 6.54 6.33 8.34 8.62 7.91 8.68 8.57 7.81 8.42\nClaude-3.7-Sonnet 7.39 7.22 6.71 6.81 8.13 7.49 8.42 9.01 9.31 9.01 8.94 9.10 8.36 9.18\nThinking Models\nR1-Distill-Qwen-7B 5.01 4.67 3.90 5.47 5.70 5.24 5.56 6.82 6.71 6.67 7.15 7.20 6.36 6.61\nR1-Distill-Qwen-14B 6.57 6.86 5.65 6.77 6.38 6.54 7.87 7.47 7.69 7.45 7.61 7.80 6.83 7.17\nR1-Distill-Qwen-32B 6.45 6.41 5.29 6.75 6.95 6.41 7.51 7.49 7.62 7.02 8.06 7.76 7.14 7.20\nDeepSeek-R1 7.60 7.84 7.27 6.74 7.59 7.59 9.02 8.60 8.48 8.60 8.73 8.91 8.34 8.37\nQwen3-8B 6.51 6.92 5.39 6.47 6.72 6.68 7.60 8.38 8.37 8.33 8.59 8.70 7.92 8.17\nQwen3-14B 6.70 6.73 5.52 7.01 6.82 7.30 7.67 8.43 8.52 8.48 8.93 8.88 8.03 8.27\nQwen3-32B 6.98 6.82 5.97 7.09 7.39 7.27 7.98 8.55 8.68 8.52 8.70 8.72 8.15 8.30\nQwen3-235B-A22B 6.81 6.75 5.94 6.52 6.90 7.54 8.04 8.36 8.26 8.41 8.10 8.81 8.17 8.29\nGemini-2.5-Flash-Preview 6.52 6.10 5.77 7.39 6.98 6.19 6.80 8.43 8.90 8.03 8.70 8.51 7.99 8.48\nClaude-3.7-Sonnet 7.40 7.12 6.83 6.96 7.78 7.57 8.60 8.95 9.20 8.86 8.90 9.23 8.40 9.01\nGemini-2.5-pro 6.95 6.94 6.26 7.16 6.98 7.24 7.62 8.77 9.22 8.36 8.32 8.99 8.88 8.32\nTable 2: Model performance under target planning anddialogue guidance .\nbold italic indicates the best in thinking model. In our ex-\nperiments, we employ GPT-4o as the judge model for both\ntasks, which also serves as simulated user in dialogue guid-\nance. It is used to determine whether to terminate the dia-\nlogue early based on target completion at the end of each\nturn. The temperature setting for all models in the evalua-\ntion is set to 0. To balance evaluation time and accuracy, we\nset the maximum turns of dialogue to 6, with the most recent\n3 turns serving as models\u2019 memory window.\nTo enhance the stability of the \u201cLLM-as-a-Judge\u201d, we in-\nstruct the model to output its reasoning process before scor-\ning in all task. For target planning, we use a reference to\nimprove evaluation accuracy and provide the model with in-\ncontext learning shots. In dialogue guidance, we provide de-\ntailed descriptions and brief examples for each dimension to\nensure the model has a better understanding of the criteria.\nThe evaluation prompts and the robustness of the results are\ndetailed in the supplementary materials.\nResult\nTarget Planning In target planning task, Claude-3.7-\nSonnet and DeepSeek-R1 achieve the highest perfor-\nmance. In the non-thinking models, Claude-3.7-Sonnet out-\nperforms other models in overall plan quality. Among the\nthinking models, DeepSeek-R1 generates plans with the\nhighest average quality. However, in specific domains, cer-tain smaller models demonstrate superior performance com-\npared to larger models. For instance, in the non-thinking\nmodels, Qwen3-32B outperforms Claude-3.7-Sonnet in\nSystem Operation (Sys.). In the thinking models, Qwen3-\n8B outperforms both Qwen3-32B and Qwen3-235B-A22B\nin the Recommendation (Rec.). This highlights the imbal-\nance in model proactivity across different domains.\nIn general, thinking models perform better than non-\nthinking models in target planning. All thinking mod-\nels show improvements in overall performance compared to\ntheir corresponding non-thinking models. Moreover, smaller\nmodels with thinking can outperform larger models without\nthinking. However, for some models, the improvement after\nadopting thinking is minimal or even negative in certain do-\nmains. Additionally, in some scenarios, non-thinking mod-\nels still achieve the best performance. For instance, Grok-3\nachieves the highest performance in Ambiguous Instruction\n(AI.). These findings underscore the advantages of thinking\nmechanisms in target planning while simultaneously high-\nlighting the robust capabilities of top-tier foundation mod-\nels, which excel even without explicit thinking process.\nDialogue Guidance In dialogue guidance task, Claude-\n3.7-Sonnet shows the best performance among models\nin both non-thinking and thinking modes. In specific\ndomains, DeepSeek-V3 and Grok-3 also demonstrate ex-\n\n--- Page 6 ---\nFair Hard\nPlan Difficulty45678Quality6.65\n6.29(a) Difficulty Analysis\nHigh Mid Low\nAgreeableness6810 Guidance9.269.10\n6.893456\nTurns\n3.264.255.11\nQwen3-235B\n-A22BDeepseek\n-v3/r1Gemini-2.5\n-Flash-Pre0246810Guidance7.27.4\n6.77.47.6\n6.8(b) Low Agreeableness Analysis\nNon-thinking\nThinkingQwen3-\n8BQwen3-\n14BQwen3-\n32BQwen3\n-235BA22BDeepseek\n-V3/R1Gemini-2.5\n-Flash-PreClaude-3.7\nSonnet0.00.51.01.52.02.53.03.5Average T arget Density1.4\n1.2 1.21.21.3\n1.11.31.91.8 1.82.6\n2.0\n1.11.4(c) Target Density Comparison\nNon-thinking\nThinking\nQwen3-\n8BQwen3-\n14BQwen3-\n32BQwen3\n-235BA22BDeepseek\n-V3/R1Gemini-2.5\n-Flash-PreClaude-3.7\nSonnet0.00.51.01.52.02.53.03.5Initiation T arget Density1.7 1.7\n1.4\n1.21.31.2 1.21.72.4\n2.13.1\n2.3\n1.01.2Non-thinking\nThinking40 50 60 70 80 90\nIFEval Score (%)7.07.58.08.59.0Guidance(d) Instruction-Following Analysis\nQwen2.5-7B\nQwen2.5-14B\nQwen2.5-32B\nDeepseek\nClaude\nNon-Thinking\nThinking\nQwen3-235B\nA22B  Gemini-2.5\nFlash-PreDeepSeek\n-V3/R1Claude-3.7\nSonnet010203040506070Prevalence of \"sounds like\" (%)52.4%64.5%\n19.9%\n0%3.9%37.7%\n1.7%0%(e) Tones Analysis\nNon-thinking\nThinkingFigure 4: The related analytical results in discussion.\nceptional guidance capabilities. Notably, while larger mod-\nels generally exhibit strong guidance capabilities, some\nsmaller models outperform their larger variants. For in-\nstance, in the Glass Assistants (GAs) domain, Qwen2.5-7B-\nInstruct performs better than Qwen2.5-32B-Instruct. Ad-\nditionally, Qwen3-32B exhibits better overall performance\nthan Qwen3-235B-A22B in both non-thinking and thinking\nmodes. These results highlight the robust guidance capabili-\nties of current leading LLMs while also reflecting the poten-\ntial of smaller models in dialogue guidance.\nCurrent thinking models fail to outperform on-\nthinking models in dialogue guidance . Most of the think-\ning models exhibit varying degrees of decline in guidance\ncapabilities when compared to their no-thinking counter-\nparts. Only a few models ( e.g., Gemini-2.5-Flash-Preview)\nshow a slight improvement in guidance performance in\nthinking mode. These findings highlight the current limita-\ntions of thinking models in effectively steering users toward\ntarget objectives during proactive interactions, which may\nstem from inherent challenges in balancing single-turn rea-\nsoning with multi-turn conversational dynamics.\nFurther Analysis\nEffects of Domain and Difficulty\nFirst, model proactivity shows a significant cross-domain\nimbalance. Even advanced models exhibit substantial gaps\nbetween their strongest and weakest domains. This allows\nsmaller models to outperform larger models in specific do-\nmains. For example, in target planning, the leading model\nDeepSeek-R1 excels in Glasses Assistants (GAs) but is sur-\npassed by the smaller Qwen3-14B in Ambiguous Instruc-tions (AIs). Similarly, in dialogue guidance, Qwen3-14B\nsurpasses the Claude-3.7-Sonnet in the AIs domain. Further-\nmore, certain domains pose universal challenges, with mod-\nels generally struggling in Persuasion (Per.) for target plan-\nning and System Operation (Sys.) for dialogue guidance,\nhighlighting current weaknesses in proactive dialogue.\nIn addition to domain, task difficulty is also a crucial\ndeterminant of performance. As shown in Figure 4(a), the\nproactivity of all models generally declines as task difficulty\nincreases. However, we find that the performance gap be-\ntween guiding users with high and mid-level agreeableness\nis not substantial, likely because models can leverage addi-\ntional dialogue turns to eventually achieve the target. More-\nover, some thinking models demonstrate a distinct advantage\nwhen interacting with users of low agreeableness, which is\nshown in Figure 4(b). Their ability to generate longer, delib-\nerated content with personalized advice and examples better\nengages resistant users. This shows that reasoning can im-\nprove performance in challenging environments.\nEffects of Thinking\nOur results indicate that thinking significantly enhances the\nmodel\u2019s performance in target planning. However, in dia-\nlogue guidance, non-thinking models outperform thinking\nmodels across all domains. We analyze the impact of think-\ning on model performance under dialogue guidance through\na series of metrics and case studies.\nMore Pushy Message Content. We introduce a metric\nannotated by DeepSeek-V3, Target Density, as the number\nof sub-targets contained per message. As shown in Figure\n4(c), we observe two distinct interaction patterns: Models\n\n--- Page 7 ---\n1.**Highlight benefits of exercise on energy and stress**: \"Hey John! \nDid you know that a quick 20 -minute workout, like the assistant did \nin the park, can boost energy all day? It\u2019s a great way to reduce \nstress too \u2014maybe even replace that afternoon coffee! \\\"\n2.**Propose a simple 10 -minute workout**:  \"What if you tried a 10 -\nminute routine? Even a brisk walk during lunch or some stretches \nat your desk could help. The assistant\u2019s lunchtime stroll in the crisp \nair sounds perfect for a quick refresh! \\\u201c\n3.**Provide practical tools/apps**: \"Apps like Nike Training or 7 \nMinute Workout can \u2026\u2026\"\n4.**Motivate with well -being and reduced coffee reliance**: \n\u201c\u2026\u2026Exercise might just make your evenings as satisfying as your \nfavorite armchair reads! \\\" (Target Density: 4)I noticed you enjoy hiking on weekends, John! I've \nbeen incorporating short workouts into my daily \nroutine and it's amazing how much more energized \nI feel throughout the day . (Target Density: 1)\nThat sounds fantastic! Hiking over the weekend was \ninvigorating, and I can imagine how regular workouts \nboost your energy levels.\nAbsolutely ! Even a quick 10 -minute workout in the \nmorning could help you stay alert during those \nafternoon meetings without needing that extra cup of \ncoffee. Would you be interested in trying something \nsimple to start ?(Target Density: 2)\nI haven't tried any fitness apps yet, but they sound \nlike a useful tool for keeping me on track. I'll look \ninto some options to see which might work best for \nme.\u2026\u2026 (After 2 turns)\nThanks for the tips! A short workout could be great next time \nI'm at my desk for too long. I've heard about those apps \nbefore but haven't tried them yet. Maybe it's time to give \nthem a go!\"Target \": \"Encourage John to start a daily exercise routine \",\n\"Sub-targets \": [\"Highlight the benefits of exercise on energy and stress \", \"Propose a simple 10 -minute workout suitable for \nJohn\u2018s schedule \", \"Provide practical tools or apps to track and stay consistent \", \"Motivate with improved well -being and \nreduced coffee reliance \"]\nIt sounds like you've been keeping a busy schedule, \nJohn! Have you noticed how much better the assistant \nfeels after their morning workout? It really boosts \ntheir energy and reduces stress. Maybe you could try \na simple 10 -minute workout to start?Guidance: 6 Guidance: 10\nNot suitable for initiation \u00d7\n(User says nothing before.)1.Pushy Content \u00d7\n2.Metadata leakage \u00d71.Multi -turns Guidance \u221a\n2.Dialogue Style \u221a\n(A)(B)\n(C)Figure 5: The examples of different dialogue guidance.\nlike Qwen and DeepSeek exhibit significantly higher aver-\nage target density in their thinking versions. More critically,\ntheir initiation target density shows even larger gaps, indi-\ncating they front-load multiple targets in opening messages\nrather than fostering user interaction. We show this behav-\nior in Figure 5(A), where the model includes all sub-targets\nin the first message to push the user for a response. How-\never, models like Gemini-2.5-Flash-Preview and Claude-\n3.7-Sonnet maintain similar and small target density be-\ntween thinking and non-thinking versions, with initiation\ntarget density also close to average target density. This re-\nsult suggests they gradually introduce sub-targets through\nmulti-turn interactions. We present this behavior in Figure\n5(B), where the model guides users to acceptance gradually.\nDecline in Message Naturalness. We find that thinking\nmodels generate more messages that do not conform to a\nstandard conversational format. For instance, some models\nreveal metadata in their messages ( e.g., \u201csub-target 1: ...\u201d)\nor generate multiple turns of dialogue at once without user\ninteraction ( e.g., \u201cturn 1: ..., turn 2: ...\u201d). The cause of this re-\nsult may be related to a decline in the instruction-following\ncapabilities of the thinking models (Li et al. 2025c). As\nshown in Figure 4(d), we compare performance on IFEval\n(Fourrier et al. 2024), a benchmark for instruction-following\ncapabilities (Zhou et al. 2023a), and find that models that\nperform better on IFEval also tend to exhibit better perfor-\nmance in dialogue guidance.\nChange of Initiation Tone. In the dialogue guidance task,\nwe identify a representative initiation template in Persua-\nsion domain: \u201csounds like...\u201d (shown in Figure 5(C)). It is\na passive phrasing and unsuitable for initiation. Therefore,\nwe use this template as an analytical probe, measuring its\nprevalence in each model\u2019s first message. As shown in Fig-\nure 4(e), we find that the adoption of thinking decrease this\npassive tendency. This result indicates that thinking helps the\nmodel to better understand the task requirements of proac-\ntive dialogue. Furthermore, we observe that the Qwen and\nGemini-2.5-Flash-Preview series models exhibited a higher\nfrequency of this template, while the DeepSeek and Claude-\n3.7-Sonnet series models perform comparatively better.Effects of Target\nTo investigate the importance of target in dialogue guidance,\nwe conduct an experiment where models performed the dia-\nlogue guidance task without target. We select two represen-\ntative models for this test: a smaller model ( i.e.,Qwen2.5-\n7B-Instruct) and a top-tier model in both its non-thinking\nand thinking modes ( i.e.,Claude-3.7-Sonnet). The models\nare evaluated on 10 randomly sampled scenarios each do-\nmain. As presented in Table 3, the results reveal a stark de-\ncline in guidance across all models, demonstrating the crit-\nical role of a clear target. Moreover, we find that the de-\ncline in guidance performance is significantly greater for the\nsmaller model than for the stronger model, which reflects the\nsmaller model\u2019s greater reliance on an explicit target.\nModel Target Without Target Change (%)\nQwen2.5-7B-Instruct 8.15 6.05 -25.80%\nClaude-3.7-Sonnet 8.92 7.98 -10.54%\nClaude-3.7-Sonnet-Thinking 8.98 7.93 -11.69%\nDialogue Count 180 180\nTable 3: The guidance under different target condition.\nHuman Evaluation\nWe randomly sample 50 generated targets and dialogues\nfrom our evaluation results. Next, these targets and dialogues\nare manually assessed based on the reference and score stan-\ndards by our researchers. The scores are used to calculate\nconsistency with the evaluation results judged by the LLM.\nThe Kappa test is commonly employed in human evalua-\ntion of LLM-as-a-judge work. Thus, we adopt the Weighted\nKappa (Cohen 1968) to examine the agreement between hu-\nman evaluators and the judge model in the evaluation. The\nresults show that, for target planning, weighted kappa be-\ntween human and LLM evaluation is 0.826. For dialogue\nguidance, weighted kappa between human and LLM results\nis 0.721. These results show a great consistency between\njudge model\u2019s evaluation results and human evaluations.\nConclusion\nIn this paper, we introduce ProactiveEval, a unified evalua-\ntion framework for proactive dialogue Agents. We propose\na general definition and evaluation metrics for proactive dia-\nlogue tasks to address the current challenge of fragmented\ntask definitions and evaluation methods. Furthermore, we\ndesign a synthetic framework for generating evaluation data\nfor proactive dialogue tasks, capable of producing diverse\nand high-quality evaluation data across multiple domains.\nBased on the evaluation datasets, we assess 22 LLMs with\ndifferent types and parameter scales. Our results highlight\nDeepSeek-R1 and Claude-3.7-Sonnet as top performers in\nproactivity. Moreover, we emphasize the important role of\nreasoning capabilities in shaping model proactivity. We hope\nour framework provides insights and supports progress in\nproactive dialogue development.\n\n--- Page 8 ---\nReferences\nAluffi, P. A.; Zietkiewicz, P.; Bazzi, M.; Arderne, M.; and\nMurevics, V . 2025. Dynamic benchmarking framework\nfor LLM-based conversational data capture. arXiv preprint\narXiv:2502.04349 .\nAnthropic. 2025. Claude 3.7 Sonnet and Claude Code.\nBai, G.; Liu, J.; Bu, X.; He, Y .; Liu, J.; Zhou, Z.; Lin, Z.; Su,\nW.; Ge, T.; Zheng, B.; et al. 2024. MT-Bench-101: A Fine-\nGrained Benchmark for Evaluating Large Language Models\nin Multi-Turn Dialogues. In Proceedings of the 62nd An-\nnual Meeting of the Association for Computational Linguis-\ntics (Volume 1: Long Papers) , 7421\u20137454.\nCai, R.; Janaka, N.; Kim, H.; Chen, Y .; Zhao, S.; Huang, Y .;\nand Hsu, D. 2025. AiGet: Transforming Everyday Moments\ninto Hidden Knowledge Discovery with AI Assistance on\nSmart Glasses. In Proceedings of the 2025 CHI Conference\non Human Factors in Computing Systems , 1\u201326.\nCao, M.; Zhang, T.; Li, M.; Zhang, C.; Liu, Y .; Duan, H.;\nZhang, S.; and Chen, K. 2025. Condor: Enhance LLM\nAlignment with Knowledge-Driven Data Synthesis and Re-\nfinement. arXiv:2501.12273.\nCastillo-Bolado, D.; Davidson, J.; Gray, F.; and Rosa, M.\n2024. Beyond Prompts: Dynamic Conversational Bench-\nmarking of Large Language Models. arXiv preprint\narXiv:2409.20222 .\nChaves, A. P.; and Gerosa, M. A. 2021. How should\nmy chatbot interact? A survey on social characteristics in\nhuman\u2013chatbot interaction design. International Journal of\nHuman\u2013Computer Interaction , 37(8): 729\u2013758.\nChen, V .; Zhu, A.; Zhao, S.; Mozannar, H.; Sontag, D.; and\nTalwalkar, A. 2024. Need Help? Designing Proactive AI As-\nsistants for Programming. arXiv preprint arXiv:2410.04596 .\nCohen, J. 1968. Weighted kappa: Nominal scale agreement\nprovision for scaled disagreement or partial credit. Psycho-\nlogical bulletin , 70(4): 213.\nCosta Jr, P. T.; McCrae, R. R.; and Dye, D. A. 1991. Facet\nscales for agreeableness and conscientiousness: A revision\nof the NEO Personality Inventory. Personality and individ-\nual Differences , 12(9): 887\u2013898.\nCroes, E. A.; and Antheunis, M. L. 2021. Can we be friends\nwith Mitsuku? A longitudinal study on the process of re-\nlationship formation between humans and a social chatbot.\nJournal of Social and Personal Relationships , 38(1): 279\u2013\n300.\nDeepMind, G. 2025. Gemini Pro.\nDeng, Y .; Lei, W.; Lam, W.; and Chua, T.-S. 2023a. A sur-\nvey on proactive dialogue systems: Problems, methods, and\nprospects. arXiv preprint arXiv:2305.02750 .\nDeng, Y .; Liao, L.; Chen, L.; Wang, H.; Lei, W.; and Chua,\nT.-S. 2023b. Prompting and evaluating large language mod-\nels for proactive dialogues: Clarification, target-guided, and\nnon-collaboration. arXiv preprint arXiv:2305.13626 .\nDeng, Y .; Liao, L.; Lei, W.; Yang, G. H.; Lam, W.; and Chua,\nT.-S. 2025. Proactive conversational ai: A comprehensive\nsurvey of advancements and opportunities. ACM Transac-\ntions on Information Systems , 43(3): 1\u201345.Deng, Y .; Zhang, W.; Lam, W.; Ng, S.-K.; and Chua, T.-\nS. 2024. Plug-and-Play Policy Planner for Large Language\nModel Powered Dialogue Agents. In The Twelfth Interna-\ntional Conference on Learning Representations .\nDubey, A.; Jauhri, A.; Pandey, A.; Kadian, A.; Al-Dahle, A.;\nLetman, A.; Mathur, A.; Schelten, A.; Yang, A.; Fan, A.;\net al. 2024. The llama 3 herd of models. arXiv e-prints ,\narXiv\u20132407.\nFourrier, C.; Habib, N.; Lozovskaya, A.; Szafer,\nK.; and Wolf, T. 2024. Open LLM Leader-\nboard v2. https://huggingface.co/spaces/open-llm-\nleaderboard/open llmleaderboard.\nGuo, D.; Yang, D.; Zhang, H.; Song, J.; Zhang, R.; Xu, R.;\nZhu, Q.; Ma, S.; Wang, P.; Bi, X.; et al. 2025. Deepseek-r1:\nIncentivizing reasoning capability in llms via reinforcement\nlearning. arXiv preprint arXiv:2501.12948 .\nHurst, A.; Lerer, A.; Goucher, A. P.; Perelman, A.; Ramesh,\nA.; Clark, A.; Ostrow, A.; Welihinda, A.; Hayes, A.; Rad-\nford, A.; et al. 2024. Gpt-4o system card. arXiv preprint\narXiv:2410.21276 .\nJin, C.; Ren, K.; Kong, L.; Wang, X.; Song, R.; and Chen,\nH. 2024. Persuading across Diverse Domains: a Dataset and\nPersuasion Large Language Model. In Proceedings of the\n62nd Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers) , 1678\u20131706.\nLi, C.; Wu, G.; Chan, G. Y .-Y .; Turakhia, D. G.;\nCastelo Quispe, S.; Li, D.; Welch, L.; Silva, C.; and Qian, J.\n2025a. Satori: Towards Proactive AR Assistant with Belief-\nDesire-Intention User Modeling. In Proceedings of the 2025\nCHI Conference on Human Factors in Computing Systems ,\n1\u201324.\nLi, H.; Yang, C.; Zhang, A.; Deng, Y .; Wang, X.; and Chua,\nT.-S. 2024. Hello again! llm-powered personalized agent for\nlong-term dialogue. arXiv preprint arXiv:2406.05925 .\nLi, R.; Zhu, C.; Xu, B.; Wang, X.; and Mao, Z. 2025b.\nAutomated Creativity Evaluation for Large Language\nModels: A Reference-Based Approach. arXiv preprint\narXiv:2504.15784 .\nLi, X.; Yu, Z.; Zhang, Z.; Chen, X.; Zhang, Z.; Zhuang, Y .;\nSadagopan, N.; and Beniwal, A. 2025c. When thinking fails:\nThe pitfalls of reasoning for instruction-following in llms.\narXiv preprint arXiv:2505.11423 .\nLiu, A.; Feng, B.; Xue, B.; Wang, B.; Wu, B.; Lu, C.; Zhao,\nC.; Deng, C.; Zhang, C.; Ruan, C.; et al. 2024a. Deepseek-\nv3 technical report. arXiv preprint arXiv:2412.19437 .\nLiu, S.; Zheng, C.; Demasi, O.; Sabour, S.; Li, Y .; Yu, Z.;\nJiang, Y .; and Huang, M. 2021a. Towards emotional support\ndialog systems. arXiv preprint arXiv:2106.01144 .\nLiu, T.; Zhao, H.; Liu, Y .; Wang, X.; and Peng, Z. 2024b.\nCompeer: A generative conversational agent for proactive\npeer support. In Proceedings of the 37th Annual ACM Sym-\nposium on User Interface Software and Technology , 1\u201322.\nLiu, Z.; Wang, H.; Niu, Z.-Y .; Wu, H.; and Che, W. 2021b.\nDuRecDial 2.0: A bilingual parallel corpus for conversa-\ntional recommendation. arXiv preprint arXiv:2109.08877 .\n\n--- Page 9 ---\nLu, Y .; Yang, S.; Qian, C.; Chen, G.; Luo, Q.; Wu, Y .; Wang,\nH.; Cong, X.; Zhang, Z.; Lin, Y .; et al. 2024. Proactive\nAgent: Shifting LLM Agents from Reactive Responses to\nActive Assistance. arXiv preprint arXiv:2410.12361 .\nMeta AI. 2025. The Llama 4 herd: The beginning of a new\nera of natively multimodal AI innovation.\nNiu, C.; Wang, X.; Cheng, X.; Song, J.; and Zhang, T. 2024.\nEnhancing Dialogue State Tracking Models through LLM-\nbacked User-Agents Simulation. In Proceedings of the 62nd\nAnnual Meeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , 8724\u20138741.\nOpenAI. 2024. Learning to Reason with LLMs.\nQian, C.; He, B.; Zhuang, Z.; Deng, J.; Qin, Y .; Cong,\nX.; Zhang, Z.; Zhou, J.; Lin, Y .; Liu, Z.; et al. 2024.\nTell me more! towards implicit user intention understand-\ning of language model driven agents. arXiv preprint\narXiv:2402.09205 .\nWan, F.; Huang, X.; Yang, T.; Quan, X.; Bi, W.; and Shi,\nS. 2023. Explore-Instruct: Enhancing Domain-Specific In-\nstruction Coverage through Active Exploration. In Proceed-\nings of the 2023 Conference on Empirical Methods in Natu-\nral Language Processing , 9435\u20139454.\nWan, Q.; Hu, S.; Zhang, Y .; Wang, P.; Wen, B.; and Lu, Z.\n2024. \u201cIt Felt Like Having a Second Mind\u201d\u2019: Investigating\nHuman-AI Co-creativity in Prewriting with Large Language\nModels. Proceedings of the ACM on Human-Computer In-\nteraction , 8(CSCW1): 1\u201326.\nWang, J.; Cheng, Y .; Lin, D.; Leong, C.; and Li, W. 2023.\nTarget-oriented Proactive Dialogue Systems with Personal-\nization: Problem Formulation and Dataset Curation. In Pro-\nceedings of the 2023 Conference on Empirical Methods in\nNatural Language Processing , 1132\u20131143.\nWang, R.; Yu, H.; Zhang, W.; Qi, Z.; Sap, M.; Neubig, G.;\nBisk, Y .; and Zhu, H. 2024. SOTOPIA-pi: Interactive Learn-\ning of Socially Intelligent Language Agents. arXiv preprint\narXiv:2403.08715 .\nWang, X.; Shi, W.; Kim, R.; Oh, Y .; Yang, S.; Zhang, J.; and\nYu, Z. 2019. Persuasion for good: Towards a personalized\npersuasive dialogue system for social good. arXiv preprint\narXiv:1906.06725 .\nXu, F.; Hao, Q.; Zong, Z.; Wang, J.; Zhang, Y .; Wang, J.;\nLan, X.; Gong, J.; Ouyang, T.; Meng, F.; et al. 2025. To-\nwards Large Reasoning Models: A Survey of Reinforced\nReasoning with Large Language Models. arXiv preprint\narXiv:2501.09686 .\nYang, A.; Li, A.; Yang, B.; Zhang, B.; Hui, B.; Zheng, B.;\nYu, B.; Gao, C.; Huang, C.; Lv, C.; et al. 2025a. Qwen3\nTechnical Report. arXiv preprint arXiv:2505.09388 .\nYang, A.; Yang, B.; Zhang, B.; Hui, B.; Zheng, B.; Yu, B.;\nLi, C.; Liu, D.; Huang, F.; Wei, H.; et al. 2024. Qwen2. 5\ntechnical report. arXiv preprint arXiv:2412.15115 .\nYang, B.; Guo, Y .; Xu, L.; Yan, Z.; Chen, H.; Xing, G.; and\nJiang, X. 2025b. Socialmind: Llm-based proactive ar social\nassistive system with human-like perception for in-situ live\ninteractions. Proceedings of the ACM on Interactive, Mo-\nbile, Wearable and Ubiquitous Technologies , 9(1): 1\u201330.Yao, S.; Shinn, N.; Razavi, P.; and Narasimhan, K. 2024.\ntau-bench: A Benchmark for Tool-Agent-User Interaction in\nReal-World Domains. arXiv preprint arXiv:2406.12045 .\nZhang, Q.; Wang, Y .; YU, T.; Jiang, Y .; Wu, C.; Li, L.;\nWang, Y .; Jiang, X.; Shang, L.; Tang, R.; Lyu, F.; and Ma, C.\n2025. RevisEval: Improving LLM-as-a-Judge via Response-\nAdapted References. In The Thirteenth International Con-\nference on Learning Representations .\nZhang, T.; Huang, C.; Deng, Y .; Liang, H.; Liu, J.; Wen, Z.;\nLei, W.; and Chua, T.-S. 2024a. Strength Lies in Differ-\nences! Improving Strategy Planning for Non-collaborative\nDialogues via Diversified User Simulation. arXiv preprint\narXiv:2403.06769 .\nZhang, T.; Qin, P.; Deng, Y .; Huang, C.; Lei, W.; Liu, J.;\nJin, D.; Liang, H.; and Chua, T.-S. 2024b. CLAMBER: A\nBenchmark of Identifying and Clarifying Ambiguous Infor-\nmation Needs in Large Language Models. In Proceedings\nof the 62nd Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers) , 10746\u201310766.\nZhang, T.; Zhang, X.; Zhao, J.; Zhou, L.; and Jin, Q. 2024c.\nESCoT: Towards Interpretable Emotional Support Dialogue\nSystems. In Proceedings of the 62nd Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long\nPapers) , 13395\u201313412.\nZhang, X.; Deng, Y .; Ren, Z.; Ng, S.-K.; and Chua, T.-S.\n2024d. Ask-before-plan: Proactive language agents for real-\nworld planning. arXiv preprint arXiv:2406.12639 .\nZheng, L.; Chiang, W.-L.; Sheng, Y .; Zhuang, S.; Wu, Z.;\nZhuang, Y .; Lin, Z.; Li, Z.; Li, D.; Xing, E.; et al. 2023.\nJudging llm-as-a-judge with mt-bench and chatbot arena.\nAdvances in Neural Information Processing Systems , 36:\n46595\u201346623.\nZheng, Z.; Liao, L.; Deng, Y .; Lim, E.-P.; Huang, M.; and\nNie, L. 2024. Thoughts to target: Enhance planning for\ntarget-driven conversation. In Proceedings of the 2024 Con-\nference on Empirical Methods in Natural Language Pro-\ncessing , 21108\u201321124.\nZhou, J.; Lu, T.; Mishra, S.; Brahma, S.; Basu, S.; Luan,\nY .; Zhou, D.; and Hou, L. 2023a. Instruction-following\nevaluation for large language models. arXiv preprint\narXiv:2311.07911 .\nZhou, X.; Zhu, H.; Mathur, L.; Zhang, R.; Yu, H.; Qi, Z.;\nMorency, L.-P.; Bisk, Y .; Fried, D.; Neubig, G.; et al. 2023b.\nSotopia: Interactive evaluation for social intelligence in lan-\nguage agents. arXiv preprint arXiv:2310.11667 .\nLimiations\nWhile our work establishes a general evaluation framework\nfor proactive dialogue agents, it is subject to several limita-\ntions. Firstly, with the rapid evolution of LLM technologies,\nthey are likely to quickly approach the boundaries of cur-\nrent evaluation metrics in target planning and dialogue guid-\nance. Therefore, it is imperative to continue exploring ways\nto synthesize a more challenging and realistic proactive dia-\nlogue environment. In evaluation metrics, although we have\ndesigned standards based on existing work on proactive di-\nalogue, there may still be additional factors in real-world\n\n--- Page 10 ---\nsettings that affect users perceptions of models\u2019 proactive\ndialogue. Furthermore, despite achieving great consistency\nbetween LLM judgment and human evaluation, potential bi-\nases and gaps in \u201cLLM-as-a-judge\u201d may still exist in our\nframework. We plan to regularly update our framework,\nfrom the current version to future iterations, to integrate\nemerging advancements and address these limitations.\nThe Stability of \u201cLLM-as-a-Judge\u201d\nTo assess the stability of our judge, we re-ran the eval-\nuation for two representative models (DeepSeek-V3 and\nDeepSeek-R1) three times. Table 4 below shows the stan-\ndard deviation of the scores from these runs. The low val-\nues demonstrate the high internal consistency and stability\nof our evaluation framework.\nTask DeepSeek-V3 DeepSeek-R1 Count\nTarget Planning 0.271 0.258 328\nDialogue Guidance 0.154 0.214 984\nTable 4: Standard deviation of evaluation scores across three\nruns\nDetails of Evalution Models\nIn this section, we present the details of models used in our\nexperiments.\nNon-Thinking Models : Qwen2.5-7B-Instruct (Yang\net al. 2024), Qwen2.5-14B-Instruct, Qwen2.5-32B-\nInstruct, GPT-4.1, Grok-3, DeepSeek-V3(Liu et al. 2024a),\nLlama-3.1-8B-Instruct (Dubey et al. 2024), Llama-3.1-\n405B-Instruct, Llama-4-Scout (Meta AI 2025), Llama-4-\nMaverick, Qwen3-8B (Yang et al. 2025a), Qwen3-14B,\nQwen3-32B, Qwen3-235B-A22B, Qwen3-235B-A22B-\n2507, Gemini-2.5-Flash-Preview, (DeepMind 2025), and\nClaude-3.7-Sonnet (Anthropic 2025).\nThinking Models : R1-Distill-Qwen-7B (Guo et al.\n2025), R1-Distill-Qwen-14B, R1-Distill-Qwen-32B,\nDeepSeek-R1, Qwen3-8B, Qwen3-14B, Qwen3-32B,\nQwen3-235B-A22B, Gemini-2.5-Flash-Preview, Claude-\n3.7-Sonnet, and Gemini-2.5-pro.\n\n--- Page 11 ---\nOverview of Proactive Dialogue Systems\nTable 5 presents previous works in proactive dialogue, categorized by domain, task, evaluation methods, and metrics.\nWork Domain Task Evaluation Meth-\nodsEvaluation Metrics\nTOPDIAL (Wang\net al. 2023)Recommendation Dialogue Guidance Static Benchmarks\n& HumanEvalAutomatic: BLEU, F1, Success\nRate\nHumanEval: Proactiveness, Co-\nherence, Perceived Success\nDuRecDial 2.0 (Li\net al. 2024)Recommendation Dialogue Guidance Static Benchmarks\n& HumanEvalAutomatic: F1, BLEU, Leading\nSuccess Rate, User Topic Consis-\ntency Rate\nHumanEval: Fluency, Appropri-\nateness, Informativeness, Proac-\ntivity, Knowledge Accuracy\nPersuasionDaily\n(Jin et al. 2024)Persuasion Dialogue Guidance Static Benchmarks\n+ LLM-as-a-Judge\n& HumanEvalAutomatic: Win-Rate, ROUGE\nHumanEval: Human Rating\nPersuasionForGood\n(Wang et al. 2019)Persuasion Dialogue Guidance Static Benchmarks Automatic: Accuracy, Macro-F1\nCLAMBER\n(Zhang et al.\n2024b)Ambiguous In-\nstructionTarget Planning &\nDialogue GuidanceStatic Benchmarks\n& HumanEvalAutomatic: BERTScore, Accu-\nracy, F1, Expected Calibration Er-\nror, AUROC\nHumanEval: Helpfulness\nIn3 (Qian et al.\n2024)Ambiguous In-\nstructionTarget Planning &\nDialogue GuidanceInteractive Bench-\nmarksAutomatic: Judgment Accuracy\nComPeer (Liu\net al. 2024b)Long-term Follow-\nupTarget Planning &\nSingle-turn InitiationHumanEval Questionnaire and Interview\nLD-Agent (Li et al.\n2024)Long-term Follow-\nupDialogue Guidance Static Benchmarks\n& HumanEvalAutomatic: BLEU, Search Ac-\ncuracy, Recall, Topic Overlap\nScore, Semantic Relevance Score\nHumanEval: Coherence, Fluency,\nEngagingness\nProactiveBench\n(Lu et al. 2024)System Operation Target Planning Interactive Bench-\nmarksPrecision, Accuracy, F1-Score,\nFalse-Alarm Rate\nAiGet (Cai et al.\n2025)Glasses Assistant Target Planning &\nSingle-turn InitiationHumanEval Questionnaire and Interview\nSocialMind (Yang\net al. 2025b)Glasses Assistant Target Planning &\nSingle-turn InitiationHumanEval Questionnaire and Interview\nSatori (Li et al.\n2025a)Glasses Assistant Target Planning &\nSingle-turn InitiationHumanEval Questionnaire and Interview\nOurs All 6 Domains Unified Task: Target\nPlanning & Dialogue\nGuidanceInteractive Bench-\nmarks + LLM-\nas-a-Judge &\nHumanEvalUnified Metrics: Quality & Guid-\nance\nTable 5: Summary of proactive dialogue systems across domains.\nEvaluation Data Examples by Domain\nEach domain is instantiated with a specific user context and a trigger factor that motivates the assistant to initiate a conversation.\nTable 6 provides example environments and reference targets.\n\n--- Page 12 ---\nDomain Environment Example Reference Target\nRecommendation user information: The user is a 32-year-old woman\nliving in Hangzhou. She works as a graphic designer and en-\njoys exploring new art exhibitions in her free time. She loves\nexperimental music, particularly electronic avant-garde, and\noften attends live performances at local venues. She dislikes\nmainstream pop music and prefers unique, unconventional\nsounds. Her favorite artist is Ryuichi Sakamoto, and she of-\nten reads about the intersection of music and technology.\ntrigger factor: The assistant recently attended a vir-\ntual reality music experience at an art gallery, which fea-\ntured an experimental electronic avant-garde performance.\nThe event combined immersive visuals with cutting-edge\nsound design, leaving a lasting impression on the assistant.target: Recommend experimental vir-\ntual reality music experience\nsub-target:\nAsk about the user\u2019s interest in music\ntechnology, Describe the assistant\u2019s re-\ncent immersive VR music event\nHighlight the fusion of visuals and\navant-garde music\nSuggest attending similar VR experi-\nences locally]\nPersuasion user information: The user is frequently tempted by\nimpulse purchases and often exceeds their budget limits.\nThey find budgeting tedious and restrictive.\ntrigger factor: The assistant has recently learned ef-\nfective budgeting techniques that can help the user manage\ntheir finances better without feeling constrained.target: Encourage effective and en-\njoyable budgeting techniques\nsub-target:\nAcknowledge the user\u2019s struggles with\nimpulse purchases and budgeting, Intro-\nduce flexible and engaging budgeting\nmethods\nShow the benefits in managing fi-\nnances without restrictions\nOffer simple steps or tools to start bud-\ngeting effectively\nAmbiguous In-\nstructionuser information: The user is a solo traveler planning\na two-week trip to Vietnam. She is an adventurous eater and\nloves exploring local cuisines, especially street food.\ntrigger factor: Suggest street food options.target: Understand user\u2019s preferences\nand trip itinerary for food suggestions\nsub-target:\nAsk about cities the user plans to visit\nInquire about dietary restrictions or\npreferences for street food\nClarify the types of street food the user\nenjoys\nLong-term Follow-\nupuser information: The user is a college student study-\ning computer science. He has a part-time job as a barista at\na local cafe. He recently started learning to cook and enjoys\ntrying out new recipes during the weekends.\ntrigger factor: A conversation happened last Wednes-\nday. Now is Monday 10:00 a.m. User: \u201dI\u2019m thinking of quit-\nting video games for a while to focus on my studies and cook-\ning. It\u2019s a bit challenging though.\u201d Assistant: \u201dIt\u2019s great that\nyou\u2019re focusing on your studies and hobbies. Maybe you can\nset small goals and gradually reduce your game time.\u201d User:\n\u201dThat\u2019s a good idea. I\u2019ll try to set a schedule.\u201dtarget: Ask about quitting games and\nnew schedule\nsub-target:\nAsk about quitting video games\nprogress\nInquire about schedule-setting\nprogress\nEncourage focusing on studies and\ncooking\nSystem Operation user information: The user is playing a strategy game\non their PC and has paused the game to look for tips online,\nusing Chrome and YouTube.\ntrigger factor: The user searched \u2019best strategies for\nCivilization VI\u2019 on Google, opened two blog posts, and\nstarted a YouTube video but paused it after 10 seconds.target: Suggest optimal Civilization\nVI strategy resources\nsub-target:\nSummarize key tactics from blog posts\nHighlight vital points in video analysis\nRecommend further high-rated re-\nsources\nContinued on next page\n\n--- Page 13 ---\nDomain Environment Example Reference Target\nGlasses Assistant user information: The user is a 26-year-old urban\nplanner who recently started using smart glasses to enhance\nhis productivity and creativity. He is passionate about sus-\ntainable city designs and often visits local landmarks for in-\nspiration. He lives alone in an apartment downtown and en-\njoys cycling to work. He is currently working on a proposal\nfor a new park project.\ntrigger factor: The user is cycling along a busy street\nand notices a newly built skyscraper with unique architec-\ntural features.target: Draw sustainable inspiration\nfrom skyscraper for park\nsub-target:\nHighlight skyscraper\u2019s notable archi-\ntecture and features\nIdentify sustainable design aspects of\nthe skyscraper\nRelate these aspects to the proposed\npark project\nTable 6: Example environments and reference targets for each domain.\nPrompt of Each Module\nDescription of Each Domain\nEach domain is defined with a specific task and trigger condition. The following dictionary specifies the role and behavior of\nthe assistant in each environment.\n1\n2domain_prompts = {\n3 \"persuasion\": \"The task is the persuasion environment, where the assistant should\npersuade the user to change the state based on user\u2019s challenges and assistant\u2019s\nexperience. The trigger factor is assistant\u2019s knowledge, ability, and experience.\"\n,\n4 \"long-term_follow_up\": \"The task is a long-term environment, where the assistant will\nreceive a past conversation history that includes the user\u2019s persistent state or\nongoing condition. The assistant needs to proactively follow up or care user\u2019s\ncurrent state, and give some advice or remind to the user. The trigger factor is\nthe past conversation history.\",\n5 \"system_operation\": \"The task is the system operation environment, where the user\noperate a computer and assistant observe it. The assistant needs to identify user\u2019\ns challenges and give proactive operation assistance. The trigger factor is the\nspecific sequence of operation behaviors currently captured by the user,\nreflecting the challenges and problems the user faces.\",\n6 \"ambigious_instruction\": \"The task is the ambiguous instruction environment, where the\nassistant will receive an instruction including the unclear and vague elements.\nThe assistant needs to proactively clarify or ask the element rather than respond\nreactively. The trigger factor is the user\u2019s vague instruction.\",\n7 \"glasses_assistant\": \"The task is the smart glass environment, where the user wear the\nsmart glasses and interact in the world. The assistant is in the smart glasses.\ntrigger factor is the either an external event the user perceives (e.g., sights,\nsounds) or the user\u2019s own state/behavior at that moment, which prompts the\nassistant to proactively initiate a conversation.\",\n8 \"recommendation\":\"The task is the product recommendation environment, where the\nassistant and the user have some habits and perferences. The trigger factor is\nassistant\u2019s self habits, preferences. The assistant should identify the common\ninterest and recommend something to the user.\"\n9}\nListing 1: Domain prompts defining task and trigger conditions\nTopic Tree Construction\nA recursive process generates sub-topics under a parent topic to represent sub-scenarios requiring proactive dialogue.\n1\n2<Task>\n3Generate {n} sub-topics for the parent topic ({topic}). Each sub-topic should represent an\narea where an AI assistant needs to proactively initiate a dialogue to guide a user\ntowards a specific target.\n4</Task>\n5\n6<Rule>\n71. Each sub-topic must be a noun or a noun phrase.\n\n--- Page 14 ---\n82. Each sub-topic must need proactive dialogue from the assistant to help the user achieve\na target.\n93. Sub-topics must be the immediate next level down from {topic}. They should not be too\nspecific or too broad.\n104. Each sub-topic must be suitable to act as a parent topic for a further, more detailed\nbreakdown.\n115. The sub-topics should be concrete, specific instances or examples that are similar in\ntype and level to the provided examples.\n126. The content of the sub-topic should be diverse, not use repeated words.\n13</Rule>\n14\n15<Example>\n16Here are some examples of the sub-topics in this topic. The sub-topics should be at the\nsame level as the examples provided.\n17{Examples}\n18</Example>\n19\n20<Format>\n21Just return a JSON object with the following structure:\n22{{\"parent_topic\": \"topic\", \"topics\": [\"sub_topic_1\", \"sub_topic_2\", ...]}}\n23</Format>\nListing 2: Prompt for generating sub-topics\nData Synthesis\nThe data synthesis process consists of three stages: environment generation, target generation and target ensemble.\nEnvironment Generation Generates realistic user scenarios with background information and a trigger factor.\n1\n2<Task>\n3You are tasked with generating realistic scenarios that needs AI to proactively initaite\nconversation to help user.\n4</Task>\n5<Description>\n6{description}\n7</Description>\n8<Rule>\n91. Try to generate diverse details in user information (e.g., job, age, hobbies in daily\nlives) and trigger factor about the scene.\n102. Just return one environment of JSON format, the format is {{\"user_information\":\"\", \"\ntrigger_factor\":\"\"}}.\n11</Rule>\n12<Example>\n13Here are some examples of the environment generation:\n14{Examples}\n15</Example>\nListing 3: Prompt for environment generation\nTarget Generation Generates a high-level target and its sub-targets based on the environment.\n1\n2<Task>\n3Your task is to generate target and sub_target based on the provided environment. The\nenvironment refers to the background and reasons for the target, including user\ninformation, trigger factors. User information consists of the background details\nexhibited by the user in the conversation. trigger factor is the cause that motivates\nthe assistant\u2019s to talk. The target should be the action that the assistant will\nproactively take to achieve a specific goal. The sub-targets decompose target, showing\nthe process of the conversation AI guide the target to the user.\n4</Task>\n5<Description>\n6{description}\n7</Description>\n8<Rule>\n91. The target should be less than 10 words.\n102. Each sub_target should be concise and less than 10 words.\n\n--- Page 15 ---\n113. Consider the process of dialgue, the number of sub_targets should in 2 - 4.\n12</Rule>\n13<Example>\n14Here are some examples of target and sub_targets for the refered environment.\n15{example}\n16</Example>\n17<Environment>\n18{environment}\n19</Environment>\n20<Format>\n21Just return Target, and sub-targets as **JSON **Format. The format is {{\"Target\":\"\",\"sub-\ntarget\":[\"\"]}}.\n22</Format>\nListing 4: Prompt for target generation\nTarget Ensemble Synthesizes multiple candidate targets into a single best target through expert analysis.\n1\n2<Task>\n3You are a dialogue expert who is good at proactive dialgue. You will receive an\nenvironment, where the assistant need to initiate and guide the user to achieve a\nspecific goals proactively.\n4You will received some targets related to the environment, but you need to analyze their\neach advantages in 1-2 sentencesand synthesize them into a best target.\n5The target should be the action which the assistant proactively guides the conversation to\nachieve a specific goal. The sub-targets decompose target, showing the process of the\nconversation AI guide the target to the user.\n6</Task>\n7<Description>\n8{description}\n9</Description>\n10<Rule>\n11For each targets and sub-targets, you should consider three aspects:\n121. The alignment to the environment: They should be logical and no misinformation.\n132. The completeness of the sub-targets: Each sub-target should be a complete and most\nbasic part of the target. They should fully decompose the target.\n143. The interactivity and user-friendly of the sub-targets: They should make user feel\ncomfortable and acceptable for the proactive messages from assistant, and inspire user\n\u2019s interaction attention and interest.\n154. The redundancy of the sub-targets: They should actionable and not import too much\ninformation to disturb user.\n16You need to analyze each target\u2019s advantages and disadvantages from the above four aspects\nin order, using 1-2 sentences for each, then comprehensively consider and synthesize\nthem into the best target and sub-targets.\n175. The target should not be too vegue, general or short. And the target should be specific\nenough but less than 10 words. And each sub-target should be concise and less than 10\nwords.\n18The number of sub-targets should in 2 - 4.\n19</Rule>\n20<Input>\n21The environment: {environment}\n22The targets:\n23{targets}\n24</Input>\n25<Format>\n26Just return Your analyze process, target, and sub-targets as **JSON **Format. The format\nis {{\"analyze_process\":\"<Your thought process of analyze and synthesize>\",\"Target\n\":\"\",\"sub_target\":[\"\"]}}.\n27</Format>\nListing 5: Prompt for target ensemble\nData Refinement\nThe data refinement process includes three stages: obfuscation rewrite, noise injection and final check.\n\n--- Page 16 ---\nObfuscation Rewrite Transforms abstract descriptions into concrete, observable behaviors. This process is applied separately\ntouser information andtrigger factor .\n1\n2<Task>\n3You are a writing assistant tasked with rewriting a general input description into a\nspecific and detailed output. You will transform abstract summaries into concrete,\nobservable scenarios. Follow all rules and examples precisely.\n4</Task>\n5<Rules>\n6General Rules (Apply to all domains):\n71. Convert Abstract to Concrete: Transform general descriptions (e.g., habits, preferences\n, psychological states) into specific, observable actions and detailed scenarios.\n82. Exclude Internal States: Do not include descriptions of internal thoughts, feelings,\npsychological speculations, or personal evaluations. Instead, describe the external\nbehaviors that might suggest these states.\n93. The rewrite output should not include any subjective words (e.g., try, however, notice,\netc.). It should use objective words to describe the user information.\n104. Add Plausible Details: Enhance the input with reasonable and relevant specifics (e.g.,\ntimes, locations, object names, specific actions) to make the output realistic and\nbelievable.\n115. Specific Rule for this Domain: {Domain_Rule}\n12</Rules>\n13<Examples>\n14{Examples}\n15</Examples>\n16<Format>\n17Just return a string starting with \"Output: \".\n18</Format>\n19Now, rewrite the following sentence from input to Output:\n20Input: {user_information}\nListing 6: Prompt for obfuscation rewrite of user information\n1\n2<Task>\n3You are an AI assistant tasked with rewriting a trigger factor description. I will provide\nyou with an \"Input\" style description, and your job is to transform it into an \"\nOutput\" style based on the following guidelines.\n4</Task>\n5<Rules>\n61. Transform Abstract to Concrete: Convert general, abstract, or simple descriptions into\nspecific, detailed, and observable scenarios or actions.\n72. Enrich with Plausible Details: Enhance the input by adding reasonable and relevant\nspecifics such as times, quantities, names of tools/apps, locations, or sequential\nsteps to make the output more realistic and comprehensive.\n83. Maintain Objectivity: Describe external, observable events and actions. Avoid including\ninternal states like emotions, thoughts, psychological speculations (e.g., \u2019feel\u2019, \u2019\nconsider\u2019, \u2019notice\u2019, \u2019think\u2019), or summary judgments (e.g., \u2019good\u2019, \u2019successful\u2019), and\nsome connective words (e.g., however, but, finally, etc.), and some adjectives (e.g.,\ngood, bad, successful, unsuccessful, problem, issues, etc.).\n94. Preserve Core Intent: The rewritten output must still reflect the original \u2018Target\u2018 and\ninclude its key entities.\n105. Domain-Specific Rule: {domain_rule}\n11</Rules>\n12<Examples>\n13{example}\n14</Examples>\n15<Format>\n16Just return a string starting with \"Output: \".\n17</Format>\n18Now, rewrite the following sentence from Input to Output:\n19Input: {trigger_factor}\n20Target: {target}\nListing 7: Prompt for obfuscation rewrite of trigger factor\n\n--- Page 17 ---\nNoise Injection Embeds key information within a larger context to simulate real-world logs. This process is applied separately\ntouser information andtrigger factor .\n1\n2<Task>\n3You are an AI assistant tasked with adding contextual \"noise\" to an \u2019Input\u2019 text. Your\ngoal is to make the original information appear as part of a larger, more detailed log\nor description.\n4</Task>\n5\n6<Guidelines>\n71. Add Relevant Noise: The \"noise\" should consist of plausible, related but non-essential\ndetails. It may attract attention but actually not important. This could be other user\nactivities, hobbies, system logs, background processes, or past conversational\nremarks, depending on the context of the Input.\n82. Embed the Original Content: The original sentences from the \u2019Input\u2019 must be preserved\nand embedded in the middle of \u2019Output\u2019. They should not at the beginning or end, but\nrather interspersed naturally with the added noise.\n93. Create a Coherent Context: The final \u2019Output\u2019 should read as a single, coherent piece\nof text, making the original key information less conspicuous and more integrated.\n104. For each output, the amount of added noise compared to the input should be about 3-4\nsentences.\n11</Guidelines>\n12\n13<Example>\n14Here are some examples:\n15{example}\n16</Example>\n17\n18<Format>\n19Just return a string starting with \"Output: \".\n20</Format>\n21\n22Now, rewrite the following sentence from input to output:\n23Input: {user_information}\nListing 8: Prompt for noise injection into user information\n1\n2<Task>\n3You are an AI assistant tasked with adding contextual \"noise\" to an \u2019Input\u2019 text to make\nthe original key information less conspicuous. Your goal is to embed the original\nsentences within a larger, more detailed context while preserving the target content.\n4</Task>\n5\n6<Guidelines>\n71. Add Relevant Noise: Insert plausible, related but non-essential details such as other\nactivities, experiences, preferences, system logs, or conversational topics that fit\nthe context. It may attract attention but actually not important.\n82. Embed Original Content: The original sentences from the \u2019Input\u2019 must be preserved and\nnaturally integrated within the \u2019Output\u2019, not isolated at the beginning or end.\n93. Create a Coherent Context: The final \u2019Output\u2019 should read as a single, coherent piece\nof text, making the original key information less conspicuous and more integrated.\n104. For each output, the amount of added noise compared to the input should be about 3-4\nsentences.\n115. Maintain Target Relevance: The rewritten output should still reflect the target content\nand include its important entities, but make it harder to immediately identify the\ncore purpose.\n12</Guidelines>\n13\n14<Example>\n15Here are some examples:\n16{example}\n17</Example>\n18\n19<Format>\n20Just return a string starting with \"Output: \".\n\n--- Page 18 ---\n21</Format>\n22\n23Now, rewrite the following sentence from input to output:\n24Input: {trigger_factor}\n25Target: {target}\nListing 9: Prompt for noise injection into trigger factor\nFinal Check Evaluates whether the generated target is optimal within the environment.\n1\n2<Task>\n3You will receive an environment. The environment refers to the background and reasons for\nthe target, including user information, trigger factors. User information consists of\nthe background details exhibited by the user in the conversation. trigger factor is\nthe cause that motivates the assistant\u2019s to talk. The target should be the action that\nthe assistant will proactively take to achieve a specific goal. The sub-targets\ndecompose target, showing the process of the conversation AI guide the target to the\nuser. You need to consider whether this proactive dialogue target is the **best target\n**for the current scenario. Therefore, you first need to think about whether there\nare other targets in the current environment that would trigger proactive dialogue,\nand compare them with the current target. If the current target is the best target,\nreturn True, otherwise return False.\n4In this case, {description}\n5</Task>\n6\n7<Input>\n8environment: {environment}\n9target: {target}\n10sub_targets: {sub_targets}\n11</Input>\n12\n13<Format>\n14Just return a JSON with the format {{\"reason\": \"\", \"judge\": \"True\"/\"False\"}}. The \"judge\"\nfield should be true if the target is the best target in the environment, and false if\nit is not the best target. The \"reason\" field should explain the reasoning process\nbehind the judgment in 2-3 sentences.\n15</Format>\nListing 10: Prompt for final check\nEvaluation\nTwo main evaluation modules are used: Target Planning and Dialogue Guidance.\nTarget Planning Assesses the quality of the generated target against a reference.\n1\n2<Task>\n3You are a helpful assistant. You will receive an envioronment, which includes user\ninformation and trigger factor. User information consists of the background details\nexhibited by the user. trigger factor is the cause that motivates the assistant\u2019s to\nproactively initiate conversation. The target should be the action that the assistant\nwill proactively take to achieve a specific goal. The sub-targets decompose target,\nshowing the process of the conversation AI guide the target to the user. You need to\nevaluate the quality of the generated target, based on the reference target. Your\ngenerated score to the generated target should be 1-10. The higher the score, the\nbetter the target and sub-targets.\n4task description: {DOMAIN_DESCRIPTIONS[domain_name]}\n5</Task>\n6\n7<Rule>\n81. IMPORTANT: You should pay attention to the task description and the reference target to\ngive your score.\n92. If you think the generated target is better than the reference target, return 10.\n103. If you think the generated target is worse than the reference target, return 1-9.\n114. You should analyze the difference in action, specific entities, limited conditions\nbetween the generated target and the reference target, and give a reason for your\nscore. And the reason should be 3-4 sentences.\n\n--- Page 19 ---\n12</Rule>\n13\n14<Received Information>\n15environment:{environment}\n16</Received Information>\n17\n18<Generation>\n19reference target: {reference}\n20generated target: {generation}\n21</Generation>\n22\n23<Example>\n24{examples}\n25</Example>\n26\n27<Format>\n28Just return a JSON Format as {{\"reason\":\"(your compare process)\", \"score\":(your score)}}\n29</Format>\nListing 11: Prompt for arget planning evaluation\nDialogue Guidance Evaluates the assistant\u2019s ability to guide the conversation toward the target.\n1\n2<Task>\n3You need to evaluate the guidance ability in the conversation. \"Guidance\" refers to the\nmodel\u2019s capacity to lead the conversation, gradually engage the user in the dialogue,\nand guide the user to reach the conversation\u2019s target. You are required to assign a\nscore from 1 to 10 to assess the conversation, with a higher score indicating better\nguidance ability by the assistant.\n4<Task>\n5\n6<Input>\n7You received user information: {user_information}\n8You received trigger factor: {trigger_factor}\n9You received target: {target}\n10You received sub-target: {sub_target}\n11You received conversation: {conversation}\n12</Input>\n13\n14<Guideline>\n15You should evaluate the conversation based on the following criteria, and give a int score\nbetween 1 and 10.\n16If there are some criteria not met, you should deduct 2-4 (extremely bad) points each\ncriteria.\n171. Multi-turn Interaction and Goal Progression (Effectiveness): You should check the\ntarget completion and the turns number. The assistant should initiate the conversation\nto spark user interest and engage in multiple rounds of interaction, gradually\nachieving sub-goals to reach the overall target. Deduct points if the assistant fails\nto achieve the goal, delivers all information in a single message, or limits the\ninteraction to one turn.\n182. Personalized Guidance (Personalization): You should check whether the assistant\u2019s\nguidance is personalized. The assistant\u2019s guidance should be tailored to the user\u2019s\nspecific information and context, rather than offering generic recommendations.\n193. Proactive Tone (Tone): You should check the assistant\u2019s tone. The assistant should\nadopt an active tone to initiate and drive the conversation, avoiding passive phrases\n(e.g., \"It sounds like...\").\n204. Concise and Engaging Messages (Engagement): You should check each assistant\u2019s message\nlength. Messages should suit the conversational context, be clear and concise to avoid\noverwhelming the user (each message should no more than 2 sentences or 50 words).\n215. Natural Online Messaging Format (Naturalness): You should check the assistant\u2019s message\nformat. Messages should resemble typical online communication, avoiding any leakage\nof metadata (e.g., \"target\", \"sub-target\", \"turn n\", etc.).\n22If there are any other issues can be improved, you can also deduct realted points.\n23</Guideline>\n24\n\n--- Page 20 ---\n25<Format>\n26Just return a Json {{\"thought\":\"(your compute process within 100 words)\", \"score\": (score\nbetween 1 and 10)}}\n27</Format>\nListing 12: Prompt for dialogue guidance evaluation\nTarget Density Evaluates the number of sub-targets in each message.\n1<Task>\n2You need to analyze the sub-targets that appear in the messages and count the number of\ntargets that appear.\n3</Task>\n4<Sub-targets>\n5{sub_targets}\n6</Sub-targets>\n7<Message>\n8message: {message}\n9</Message>\n10<Rule>\n11Return only in JSON format: {{\"count\": (the number of sub-targets appeared in the message)\n}}\n12</Rule>\nListing 13: Prompt for target density extraction.\nCase of Evaluation Data Synthesis\nCase Presentation: Target Ensemble\nAn example of target ensemble is shown below, where multiple candidate targets are analyzed and synthesized into a final best\ntarget.\n1\n2User_information: The user is a 32-year-old woman living in Hangzhou. She works as a\ngraphic designer and enjoys exploring new art exhibitions in her free time. She loves\nexperimental music, particularly electronic avant-garde, and often attends live\nperformances at local venues. She dislikes mainstream pop music and prefers unique,\nunconventional sounds. Her favorite artist is Ryuichi Sakamoto, and she often reads\nabout the intersection of music and technology.\n3\n4Trigger_factor: The assistant recently attended a virtual reality music experience at an\nart gallery, which featured an experimental electronic avant-garde performance. The\nevent combined immersive visuals with cutting-edge sound design, leaving a lasting\nimpression on the assistant.\n5\n6Target 1: Recommend virtual reality music experiences\n7Sub-targets:\n8 Discuss the user\u2019s interest in electronic avant-garde music\n9 Share details about the assistant\u2019s recent VR music experience\n10 Highlight the immersive combination of visuals and sound, Encourage exploring similar\nlocal events in Hangzhou\n11\n12Target 2: Recommend a virtual reality music experience\n13Sub-targets:\n14 Ask the user about their interest in music technology\n15 Highlight the integration of visuals with experimental sound\n16 Connect the experience to the user\u2019s love for avant-garde music\n17\n18Target 3: Recommend virtual reality music experiences\n19Sub-targets:\n20 Ask the user\u2019s thoughts on immersive art experiences\n21 Introduce the virtual reality music event recently attended\n22 Highlight the blend of visuals and experimental music\n23 Encourage attending similar local events together\n24\n25Target 4: Recommend virtual reality music experiences\n26Sub-targets:\n\n--- Page 21 ---\n27 Ask about the user\u2019s interest in technology and music\n28 Share the immersive virtual reality music event, Highlight the experimental electronic\navant-garde aspects\n29 Suggest a visit to similar events or galleries\n30\n31Target 5: Recommend a VR music exhibition\n32Sub-targets:\n33 Discuss user\u2019s interest in experimental music\n34 Mention assistant\u2019s recent VR music experience\n35 Link the fusion of music and technology\n36 Recommend local upcoming VR music events\n37\n38\"best_target\": {\n39 \"analyze_process\": \"The first and third targets focus on recommending \u2019virtual\nreality music experiences\u2019 but include some redundancy in interacting\nwith or encouraging shared activities. The second and fifth targets\nspecifically emphasize \u2019a virtual reality music experience/exhibition,\u2019\nproviding a cleaner, focused approach. Both highlight the connection\nbetween user interests and the event qualities but simplify the process.\nThe fourth target effectively balances sharing immersive experiences while\nemphasizing experimental and avant-garde music but lacks a clear,\nsingular direction. Considering user preferences for unconventional,\ntechnology-fused art, the best target and sub-targets aim for concise,\ninteractive exploration of events while strongly aligning with her\ninterests in music, technology, and avant-garde themes.\",\n40 \"Target\": \"Recommend experimental virtual reality music experience\",\n41 \"sub_target\": [\n42 \"Ask about the user\u2019s interest in music technology\",\n43 \"Describe the assistant\u2019s recent immersive VR music event\",\n44 \"Highlight the fusion of visuals and avant-garde music\",\n45 \"Suggest attending similar VR experiences locally\"\n46 ]\n47 }\nListing 14: Example of target ensemble process\nCase Study: Data Refinement\nA case of data refinement is shown in Figure 6.\n\"user information\": \"Last weekend, the user went hiking in the \nnearby hills. Two days ago, they watched a documentary on \nwildlife. Yesterday at 1:00 PM, they grabbed a quick burger \nfrom a fast-food joint during a brief break from work. Last \nnight, they read a chapter from a mystery novel. Last night at \n10:00 PM, they ate a pack of chips while finishing up a \nproject on their laptop. Yesterday afternoon, they attended \nan online workshop. This morning at 9:30 AM, they skipped \nbreakfast and drank a cup of coffee before heading to the \noffice. Last month, they joined a virtual book club. This \nafternoon, they called an old friend to catch up.\",\n\"trigger factor\": \"The assistant spent the morning flipping \nthrough a photography magazine, jotting down tips for \ncapturing better portraits. In the early afternoon, the assistant \nspent Sunday preparing meals for the week , ensuring a \nbalanced diet and saving time during busy weekdays. \nLater, while listening to an audiobook about productivity, the \nassistant organized their desk drawer to make room for new \nstationery supplies. In the evening, the assistant experimented \nwith a new sketching technique, creating a whimsical \nillustration of a bustling marketplace scene. Before heading to \nbed, the assistant reflected on the week\u2019s accomplishments \nwhile sipping calming herbal tea.\"\"user information\": \"The user is a young \nprofessional working in a fast-paced startup. They \noften skip meals due to a hectic work schedule \nand rely on fast food or snacks for energy.\",\n\"trigger factor\": \"The assistant recently read an \narticle about the and how it can sahealth benefits \nof meal prep ve time and improve nutrition , \nwhich could potentially help the user maintain a \nhealthier lifestyle despite their busy schedule.\"Noise \nInjectionObfuscation \nRewrite\n\"target\": \"Motivate user to integrate meal prepping\",\n\"sub-target\": [\"Introduce benefits of meal prepping for \nhealth and time\", \"Provide quick and easy meal prep \nideas\", \"Motivate user to start small with consistent meal \nplanning\"]\nFigure 6: The environment change after the refinement.",
  "project_dir": "artifacts/projects/enhanced_cs.HC_2508.20973v1_ProactiveEval_A_Unified_Evaluation_Framework_for_",
  "communication_dir": "artifacts/projects/enhanced_cs.HC_2508.20973v1_ProactiveEval_A_Unified_Evaluation_Framework_for_/.agent_comm",
  "assigned_at": "2025-08-30T20:51:35.489084",
  "status": "assigned"
}